{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d185038421d60172"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T02:17:21.517255Z",
     "start_time": "2025-11-21T02:15:16.896082Z"
    }
   },
   "source": [
    "import os, yaml, shutil, glob\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 1. DOWNLOAD DATASETS ---\n",
    "\n",
    "rf = Roboflow(api_key=\"BJDNkOnpT2z6XuaFpI94\") # REPLACE WITH YOUR NEW KEY IF YOU REVOKED THE OLD ONE\n",
    "\n",
    "# Dataset 1: Accessible-Toilets\n",
    "p1 = rf.workspace(\"image-bounding-for-datasets\").project(\"accessible-toilets\")\n",
    "v1 = p1.version(1)\n",
    "ds1 = v1.download(\"yolov8\")\n",
    "\n",
    "# Dataset 2: Bathroom-SDSNE\n",
    "p2 = rf.workspace(\"adrian-gorcea\").project(\"bathroom-sdsne\")\n",
    "v2 = p2.version(2)\n",
    "ds2 = v2.download(\"yolov8\")\n",
    "\n",
    "# Dataset 3: Door-handle (FIXED)\n",
    "p3 = rf.workspace(\"new-workspace-vjwug\").project(\"door-handle-hzojf\")\n",
    "v3 = p3.version(1)        # Changed from p2 to p3\n",
    "ds3 = v3.download(\"yolov8\") # Changed from v2 to v3\n",
    "\n",
    "\n",
    "# --- 2. DEFINE MAPPINGS ---\n",
    "\n",
    "# Mapping for dataset 1 (Accessible Toilets)\n",
    "dataset1_map = {\n",
    "    0: 1,   # grab_handle -> class 1\n",
    "    1: 0,   # toilet      -> class 0\n",
    "    2: 6    # wheelchair  -> class 6\n",
    "}\n",
    "\n",
    "# Mapping for dataset 2 (Bathroom SDSNE)\n",
    "dataset2_map = {\n",
    "    0: 2,    # mirror\n",
    "    1: 3,    # sink\n",
    "    2: 4,    # soap\n",
    "    3: 5,    # towel\n",
    "    4: None, # DELETE garbage\n",
    "    5: 0     # wc -> toilet\n",
    "}\n",
    "\n",
    "# Mapping for dataset 3 (Door Handle) -> NEW CLASS 7\n",
    "# Assuming Dataset 3 has only one class \"door-handle\" at index 0\n",
    "dataset3_map = {\n",
    "    0: 7     # door-handle -> class 7 (New Class)\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. REWRITE LABELS ---\n",
    "\n",
    "def rewrite_labels(folder, id_map):\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Skipping {folder} (not found)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing labels in: {folder}\")\n",
    "    for f in os.listdir(folder):\n",
    "        if not f.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        old_path = os.path.join(folder, f)\n",
    "        new_lines = []\n",
    "\n",
    "        with open(old_path) as fp:\n",
    "            for line in fp:\n",
    "                parts = line.strip().split()\n",
    "                old_id = int(parts[0])\n",
    "\n",
    "                if old_id not in id_map:\n",
    "                    continue\n",
    "                new_id = id_map[old_id]\n",
    "                if new_id is None:\n",
    "                    continue\n",
    "\n",
    "                new_lines.append(\" \".join([str(new_id)] + parts[1:]))\n",
    "\n",
    "        with open(old_path, \"w\") as fp:\n",
    "            fp.write(\"\\n\".join(new_lines))\n",
    "\n",
    "# Apply to Dataset 1\n",
    "for split in [\"train\", \"test\", \"valid\"]:\n",
    "    rewrite_labels(f\"{ds1.location}/{split}/labels\", dataset1_map)\n",
    "\n",
    "# Apply to Dataset 2\n",
    "for split in [\"train\", \"test\", \"valid\"]:\n",
    "    rewrite_labels(f\"{ds2.location}/{split}/labels\", dataset2_map)\n",
    "\n",
    "# Apply to Dataset 3 (New)\n",
    "for split in [\"train\", \"test\", \"valid\"]:\n",
    "    rewrite_labels(f\"{ds3.location}/{split}/labels\", dataset3_map)\n",
    "\n",
    "\n",
    "# --- 4. MERGE FOLDERS ---\n",
    "\n",
    "# Create combined structure\n",
    "for t in [\"train\", \"valid\", \"test\"]:\n",
    "    os.makedirs(f\"combined/images/{t}\", exist_ok=True)\n",
    "    os.makedirs(f\"combined/labels/{t}\", exist_ok=True)\n",
    "\n",
    "def merge(src, split):\n",
    "    img_s = f\"{src}/{split}/images\"\n",
    "    lbl_s = f\"{src}/{split}/labels\"\n",
    "    img_d = f\"combined/images/{split}\"\n",
    "    lbl_d = f\"combined/labels/{split}\"\n",
    "    \n",
    "    if os.path.exists(img_s):\n",
    "        shutil.copytree(img_s, img_d, dirs_exist_ok=True)\n",
    "    if os.path.exists(lbl_s):\n",
    "        shutil.copytree(lbl_s, lbl_d, dirs_exist_ok=True)\n",
    "\n",
    "# Merge all 3 datasets\n",
    "# We use ds.location to ensure we get the exact folder name Roboflow downloaded\n",
    "for split in [\"train\", \"test\", \"valid\"]:\n",
    "    merge(ds1.location, split)\n",
    "    merge(ds2.location, split)\n",
    "    merge(ds3.location, split)\n",
    "\n",
    "\n",
    "# --- 5. CREATE YAML ---\n",
    "\n",
    "combined_yaml = {\n",
    "    \"train\": \"combined/images/train\",\n",
    "    \"val\": \"combined/images/valid\",\n",
    "    \"test\": \"combined/images/test\",\n",
    "    \"names\": [\n",
    "        \"toilet\",          # 0\n",
    "        \"grab_handle\",     # 1\n",
    "        \"mirror\",          # 2\n",
    "        \"sink\",            # 3\n",
    "        \"soap\",            # 4\n",
    "        \"towel\",           # 5\n",
    "        \"wheelchair_logo\", # 6\n",
    "        \"door-handle\"      # 7 (NEW FROM DATASET 3)\n",
    "    ],\n",
    "    \"nc\": 8 # Total classes\n",
    "}\n",
    "\n",
    "with open(\"combined.yaml\", \"w\") as f:\n",
    "    yaml.dump(combined_yaml, f)\n",
    "\n",
    "\n",
    "# --- 6. TRAIN ---\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"combined.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8\n",
    ")\n",
    "\n",
    "# --- 7. INFERENCE ---\n",
    "\n",
    "from ipywidgets import FileUpload\n",
    "\n",
    "# Reload best model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "print(\"Corrected Classes:\", model.model.names)\n",
    "\n",
    "# Create uploader\n",
    "uploader = FileUpload(accept='image/*', multiple=False)\n",
    "display(uploader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Door-handle-1 to yolov8:: 100%|██████████| 20340/20340 [00:00<00:00, 28759.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Door-handle-1 in yolov8:: 100%|██████████| 1148/1148 [00:00<00:00, 1905.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\Accessible-Toilets-1/train/labels\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\Accessible-Toilets-1/test/labels\n",
      "Skipping C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\Accessible-Toilets-1/valid/labels (not found)\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\bathroom-2/train/labels\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\bathroom-2/test/labels\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\bathroom-2/valid/labels\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\Door-handle-1/train/labels\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\Door-handle-1/test/labels\n",
      "Processing labels in: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\Door-handle-1/valid/labels\n",
      "Ultralytics 8.3.229  Python-3.12.3 torch-2.9.1+cpu CPU (AMD Ryzen 9 6900HS with Radeon Graphics)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=combined.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Ryan.H\\PycharmProjects\\DataGenerator\\runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.10.1 ms, read: 3.71.5 MB/s, size: 24.4 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\combined\\labels\\train... 1699 images, 37 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1699/1699 469.5it/s 3.6s0.1s\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\combined\\labels\\train.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 1560, len(boxes) = 5268. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.10.0 ms, read: 4.82.3 MB/s, size: 28.7 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\combined\\labels\\valid... 170 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 170/170 461.0it/s 0.4s0.1s\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\Ryan.H\\PycharmProjects\\Toilet-Accessibility-Detection\\combined\\labels\\valid.cache\n",
      "Plotting labels to C:\\Users\\Ryan.H\\PycharmProjects\\DataGenerator\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\Ryan.H\\PycharmProjects\\DataGenerator\\runs\\detect\\train2\u001B[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001B[K      1/100         0G      1.481      3.817      1.555         43        640: 28% ━━━───────── 59/213 1.7s/it 1:38<4:184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 149\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;66;03m# --- 6. TRAIN ---\u001B[39;00m\n\u001B[32m    147\u001B[39m model = YOLO(\u001B[33m\"\u001B[39m\u001B[33myolov8n.pt\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m149\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcombined.yaml\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m640\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m8\u001B[39;49m\n\u001B[32m    154\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m    156\u001B[39m \u001B[38;5;66;03m# --- 7. INFERENCE ---\u001B[39;00m\n\u001B[32m    158\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mipywidgets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FileUpload\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataGenerator\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:778\u001B[39m, in \u001B[36mModel.train\u001B[39m\u001B[34m(self, trainer, **kwargs)\u001B[39m\n\u001B[32m    775\u001B[39m     \u001B[38;5;28mself\u001B[39m.trainer.model = \u001B[38;5;28mself\u001B[39m.trainer.get_model(weights=\u001B[38;5;28mself\u001B[39m.model \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ckpt \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, cfg=\u001B[38;5;28mself\u001B[39m.model.yaml)\n\u001B[32m    776\u001B[39m     \u001B[38;5;28mself\u001B[39m.model = \u001B[38;5;28mself\u001B[39m.trainer.model\n\u001B[32m--> \u001B[39m\u001B[32m778\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    779\u001B[39m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[32m    780\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {-\u001B[32m1\u001B[39m, \u001B[32m0\u001B[39m}:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataGenerator\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001B[39m, in \u001B[36mBaseTrainer.train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    240\u001B[39m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataGenerator\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:434\u001B[39m, in \u001B[36mBaseTrainer._do_train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    431\u001B[39m     \u001B[38;5;28mself\u001B[39m.tloss = \u001B[38;5;28mself\u001B[39m.loss_items \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.tloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.tloss * i + \u001B[38;5;28mself\u001B[39m.loss_items) / (i + \u001B[32m1\u001B[39m)\n\u001B[32m    433\u001B[39m \u001B[38;5;66;03m# Backward\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m434\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mscaler\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    435\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ni - last_opt_step >= \u001B[38;5;28mself\u001B[39m.accumulate:\n\u001B[32m    436\u001B[39m     \u001B[38;5;28mself\u001B[39m.optimizer_step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataGenerator\\.venv\\Lib\\site-packages\\torch\\_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataGenerator\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataGenerator\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
